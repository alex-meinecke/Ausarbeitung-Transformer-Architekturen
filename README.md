# Einführung in Transformer-Architekturen neuronaler Netze

Dieses Repository enthält die schriftliche Ausarbeitung des Themas **"Einführung in Transformer-Architekturen neuronaler Netze"**, welche im Rahmen des Integrationsseminars an der DHBW Mannheim erstellt wurde.

## Inhalt

Die Arbeit beleuchtet die grundlegenden Konzepte von Transformer-Architekturen, einschließlich:
- Die Funktionsweise von Scaled Dot-Product Attention
- Multi-Head-Attention und Positional Encodings
- Der Aufbau von Encoder- und Decoder-Komponenten

## Zielgruppe

Dieses Projekt richtet sich an Interessierte, die einen Einblick in die Funktionsweise moderner neuronaler Netze für Textverarbeitung erhalten möchten.
