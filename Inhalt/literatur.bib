@misc{attention,
    title={Attention Is All You Need},
    author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
    year={2017},
    howpublished={\url{https://arxiv.org/abs/1706.03762}},
    note={Zugriff am 20. Dezember 2024}
}
@misc{krueger2022transformer,
    title={Die Transformer-Architektur für Systeme zur neuronalen maschinellen Übersetzung – eine popularisierende Darstellung},
    author={Krüger, Ralph},
    year={2021},
    howpublished={\url{https://www.researchgate.net/publication/357934738_Die_Transformer-Architektur_fur_Systeme_zur_neuronalen_maschinellen_Ubersetzung_-eine_popularisierende_Darstellung}},
    note={Zugriff am 7. Januar 2025}
}


@misc{lippe2022multihead,
    title={Transformers and Multi-Head Attention},
    author={Lippe, Phillip},
    year={2022},
    howpublished={\url{https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial6/Transformers_and_MHAttention.html}},
    note={Zugriff am 7. Januar 2025}
}

@book{Kinnebrock.2018,
 abstract = {},
 author = {Kinnebrock, Werner},
 year = {2018},
 title = {Neuronale Netze : Grundlagen, Anwendungen, Beispiel´},
 address = {Berlin},
 edition = {2., aktualisierte und erweiterte Auflage 2018},
 publisher = {{Berlin Boston Oldenbourg Wissenschaftsverlag}},
 isbn = {9783486786361}
}
@book{paass.2020,
    author={Gerhard Paaß and Dirk Hecker},
    title={Künstliche Intelligenz: Was steckt hinter der Technologie der Zukunft?},
    year={2020},
    publisher={Springer Fachmedien Wiesbaden},
    address={Wiesbaden},
    isbn={978-3-658-30211-5},
    doi={10.1007/978-3-658-30211-5},
    url={https://doi.org/10.1007/978-3-658-30211-5}
}


